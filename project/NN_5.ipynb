{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.html.widgets import interact\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "sigmoid_v = np.vectorize(sigmoid)\n",
    "\n",
    "def sigmoidprime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "sigmoidprime_v = np.vectorize(sigmoidprime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = [64, 20, 10]\n",
    "\n",
    "weights = []\n",
    "for n in range(1, len(size)):\n",
    "    weights.append(np.random.rand(size[n-1], size[n]) * 2 - 1)\n",
    "\n",
    "biases = []\n",
    "for n in range(1, len(size)):\n",
    "    biases.append(np.random.rand(size[n]) * 2 - 1)\n",
    "\n",
    "trainingdata = digits.data[0:1200]\n",
    "traininganswers = digits.target[0:1200]\n",
    "lc = 0.02\n",
    "\n",
    "#convert the integer answers into a 10-dimension array\n",
    "traininganswervectors = np.zeros((1796,10))\n",
    "for n in range(1796):\n",
    "    traininganswervectors[n][digits.target[n]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feedforward(weights, biases, a):\n",
    "    b = []\n",
    "    #first element is inputs \"a\"\n",
    "    b.append(a)\n",
    "    for n in range(1, len(size)):\n",
    "        #all other elements depend on the number of neurons\n",
    "        b.append(np.zeros(size[n]))\n",
    "        for n2 in range(0, size[n]):\n",
    "            b[n][n2] = sigmoid_v(np.dot(weights[n-1][0:,n2], b[n-1]) + biases[n-1][n2])\n",
    "      \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.,   0.,   0.,  13.,\n",
       "         15.,  10.,  15.,   5.,   0.,   0.,   3.,  15.,   2.,   0.,  11.,\n",
       "          8.,   0.,   0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.,   0.,\n",
       "          5.,   8.,   0.,   0.,   9.,   8.,   0.,   0.,   4.,  11.,   0.,\n",
       "          1.,  12.,   7.,   0.,   0.,   2.,  14.,   5.,  10.,  12.,   0.,\n",
       "          0.,   0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]),\n",
       " array([  9.90442338e-01,   2.44256528e-09,   1.00000000e+00,\n",
       "          1.00000000e+00,   5.51988812e-07,   3.78325361e-12,\n",
       "          1.00000000e+00,   9.99999971e-01,   8.37342711e-01,\n",
       "          9.99607802e-01,   9.82783336e-01,   9.99997482e-01,\n",
       "          9.57307764e-01,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.84974834e-01,   4.64684702e-03,\n",
       "          1.00000000e+00,   8.02410452e-03]),\n",
       " array([ 0.44779612,  0.87163994,  0.92769695,  0.44619154,  0.06217504,\n",
       "         0.5942893 ,  0.60903872,  0.9745915 ,  0.09787074,  0.12295571])]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedforward(weights, biases, trainingdata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent(weights, biases, inputs, answers, batchsize, lc, epochs):\n",
    "    for n in range(epochs):\n",
    "        #pick random locations for input/result data\n",
    "        locations = np.random.randint(0, len(inputs), batchsize)\n",
    "        minibatch = []\n",
    "        #create tuples (inputs, result) based on random locations\n",
    "        for n2 in range(batchsize):\n",
    "            minibatch.append((inputs[locations[n2]], answers[locations[n2]]))\n",
    "        for n3 in range(batchsize):\n",
    "            weights, biases = train(weights, biases, minibatch, lc)\n",
    "        \n",
    "        \n",
    "        results = []\n",
    "        for n4 in range(len(trainingdata)):\n",
    "            results.append(feedforward(weights, biases, inputs[n4])[-1])\n",
    "            \n",
    "        accresult = accuracy(inputs, results, answers)\n",
    "        print(\"Epoch \", n, \" : \", accresult)\n",
    "        \n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(weights, biases, minibatch, lc):\n",
    "    #set the nabla functions to be the functions themselves initially, same size\n",
    "    nb = [np.zeros(b.shape) for b in biases]\n",
    "    nw = [np.zeros(w.shape) for w in weights]\n",
    "    #largely taken from Michael Nielsen's implementation\n",
    "    for i, r in minibatch:\n",
    "        dnb, dnw = backprop(weights, biases, i, r)\n",
    "        nb = [a+b for a, b in zip(nb, dnb)]\n",
    "        nw = [a+b for a, b in zip(nw, dnw)]\n",
    "    \n",
    "    weights = [w-(lc/len(minibatch))*n_w for w, n_w in zip(weights, nw)]\n",
    "    biases = [b-(lc/len(minibatch))*n_b for b, n_b in zip(biases, nb)]\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def backprop(weights, biases, inputs, answers):\n",
    "    #set the nabla functions to be the same size as functions\n",
    "    nb = [np.zeros(b.shape) for b in biases]\n",
    "    nw = [np.zeros(w.shape) for w in weights]\n",
    "    a = inputs\n",
    "    alist = [inputs]\n",
    "    zlist = []\n",
    "    #from feedforward\n",
    "    for n in range(1, len(size)):\n",
    "        #all other elements depend on the number of neurons\n",
    "        zlist.append(np.zeros(size[n]))\n",
    "        alist.append(np.zeros(size[n]))\n",
    "        for n2 in range(1, size[n]):\n",
    "            zlist[n-1][n2] = np.dot(weights[n-1][0:,n2], alist[n-1]) + biases[n-1][n2]\n",
    "            alist[n][n2] = sigmoid_v(alist[n-1][n2])\n",
    "    \n",
    "    delta = costderivative(alist[-1], answers) * sigmoidprime_v(zlist[-1])\n",
    "    nb[-1] = delta\n",
    "    #different from MN, alist[-2] not same size as delta?\n",
    "    nw[-1] = np.dot(delta, alist[-1].transpose())\n",
    "    \n",
    "    for n in range(2, len(size)):\n",
    "        delta = np.dot(weights[-n+1], delta) * sigmoidprime_v(zlist[-n])\n",
    "        nb[-n] = delta\n",
    "        #same here\n",
    "        nw[-n] = np.dot(delta, alist[-n].transpose())\n",
    "    \n",
    "    return nb, nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def costderivative(output, answers):\n",
    "    return (output - answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(inputs, results, answers):\n",
    "    correct = 0\n",
    "    binresults = results\n",
    "    for n in range(0, len(results)):\n",
    "        #converts the output into a binary y/n for each digit\n",
    "        for n2 in range(len(results[n])):\n",
    "            if results[n][n2] == np.amax(results[n]):\n",
    "                binresults[n][n2] = 1\n",
    "            else:\n",
    "                binresults[n][n2] = 0\n",
    "        \n",
    "        if np.array_equal(answers[n], binresults[n]):\n",
    "            correct += 1\n",
    "    return correct / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = [64, 20, 10]\n",
    "\n",
    "weights = []\n",
    "for n in range(1, len(size)):\n",
    "    weights.append(np.random.rand(size[n-1], size[n]) * 2 - 1)\n",
    "\n",
    "biases = []\n",
    "for n in range(1, len(size)):\n",
    "    biases.append(np.random.rand(size[n]) * 2 - 1)\n",
    "\n",
    "trainingdata = digits.data[0:1000]\n",
    "traininganswers = digits.target[0:1000]\n",
    "\n",
    "traininganswervectors = np.zeros((1000,10))\n",
    "for n in range(1000):\n",
    "    traininganswervectors[n][digits.target[n]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  :  0.048\n",
      "Epoch  1  :  0.093\n",
      "Epoch  2  :  0.095\n",
      "Epoch  3  :  0.101\n",
      "Epoch  4  :  0.097\n",
      "Epoch  5  :  0.095\n",
      "Epoch  6  :  0.101\n",
      "Epoch  7  :  0.101\n",
      "Epoch  8  :  0.105\n",
      "Epoch  9  :  0.091\n",
      "Epoch  10  :  0.09\n",
      "Epoch  11  :  0.091\n",
      "Epoch  12  :  0.091\n",
      "Epoch  13  :  0.09\n",
      "Epoch  14  :  0.092\n",
      "Epoch  15  :  0.091\n",
      "Epoch  16  :  0.091\n",
      "Epoch  17  :  0.091\n",
      "Epoch  18  :  0.09\n",
      "Epoch  19  :  0.09\n",
      "Epoch  20  :  0.089\n",
      "Epoch  21  :  0.089\n",
      "Epoch  22  :  0.081\n",
      "Epoch  23  :  0.14\n",
      "Epoch  24  :  0.139\n",
      "Epoch  25  :  0.125\n",
      "Epoch  26  :  0.117\n",
      "Epoch  27  :  0.113\n",
      "Epoch  28  :  0.114\n",
      "Epoch  29  :  0.114\n",
      "[array([[ 0.76450383,  0.59251208, -0.33663917, ...,  0.03105159,\n",
      "        -0.50664191,  0.55243318],\n",
      "       [-0.32381734, -0.19473504,  0.47964496, ..., -0.74232456,\n",
      "         0.63391058,  0.11945287],\n",
      "       [ 0.6231575 ,  0.86058574,  0.88342131, ..., -0.22242994,\n",
      "         0.25655237, -0.23629923],\n",
      "       ..., \n",
      "       [-0.36932122, -0.3959529 ,  0.81687002, ..., -0.97764035,\n",
      "        -0.32230678,  0.12894721],\n",
      "       [ 0.3298412 ,  0.6209686 ,  0.84756657, ..., -0.12449487,\n",
      "         0.39450935, -0.18668442],\n",
      "       [-0.95583099,  0.08569311,  0.71531   , ...,  0.87901573,\n",
      "        -0.25818984, -0.67319341]]), array([[ 0.14131349, -1.45527079, -0.54529945, -1.0817927 , -1.63675429,\n",
      "        -0.82509237, -0.50577114, -1.25099751, -1.57167739, -1.58229838],\n",
      "       [-0.26268802, -0.46828519, -0.27403453, -0.27378482, -0.11569697,\n",
      "        -1.14896415, -1.0756586 , -1.00494417, -1.1274975 , -1.18015684],\n",
      "       [-0.02772253,  0.15362551, -0.73992948, -0.38885413,  0.10669895,\n",
      "        -1.04529539, -0.51262275,  0.04903211,  0.07113167, -0.95034216],\n",
      "       [-1.10066271, -0.4192437 , -0.83153843, -0.08715551,  0.0762273 ,\n",
      "        -1.61585745, -0.07269733,  0.22141072, -1.47321102, -1.06635828],\n",
      "       [-1.53605171, -0.20236728, -1.59564818, -0.7736486 , -0.85743672,\n",
      "        -1.65075395,  0.22338501, -0.41452082, -1.19489058, -0.28412976],\n",
      "       [-0.97130133, -1.26394292, -0.86485605,  0.21719278,  0.04154922,\n",
      "        -0.56971456, -1.64255665, -1.71024067, -1.65795937, -1.58724435],\n",
      "       [-1.17607687, -1.66427757, -1.26226142,  0.03540448, -0.09032715,\n",
      "        -0.57956052, -1.30498373,  0.19528167, -0.61780775, -1.71499853],\n",
      "       [-1.32944467, -0.58069153, -0.7444898 ,  0.13856652, -1.36328519,\n",
      "        -0.13302136, -1.30499062, -0.1462735 ,  0.09600149, -1.51221257],\n",
      "       [-1.2194706 , -0.23253221, -0.66908131, -0.61349542, -0.69434693,\n",
      "        -0.5319174 , -0.53994301, -1.40761353, -0.77824655, -0.47336865],\n",
      "       [-0.57874113, -1.45537269, -0.52541559,  0.00194201, -1.72241672,\n",
      "        -0.15125062, -1.50899977, -1.31169813, -0.38594925,  0.17597085],\n",
      "       [-1.15019981,  0.15592889, -0.31838663, -0.85503774, -1.15652188,\n",
      "        -0.19242718, -0.88554113, -0.27003906, -0.59227189, -0.38658356],\n",
      "       [-0.19594764, -0.27451577,  0.12450115, -1.16536117,  0.22683144,\n",
      "        -1.45717936,  0.05982142, -0.48704248,  0.16055401,  0.07586088],\n",
      "       [-1.31938199, -0.15037955, -0.54360006, -0.16815748, -0.53387818,\n",
      "        -1.06238962, -0.71740935, -1.72122009, -0.43972491, -0.02027598],\n",
      "       [-1.5115723 , -0.84107486, -1.14661439, -1.11010468, -0.39087975,\n",
      "         0.10574395, -1.70313065, -1.37999991, -1.2981514 , -0.4824089 ],\n",
      "       [ 0.17303988, -0.90082792, -0.36351988, -1.04551961, -0.80590839,\n",
      "         0.18561133,  0.1314899 , -0.74618971, -0.60030412, -1.45901202],\n",
      "       [ 0.25517938, -1.462488  , -1.29089867, -0.52794909,  0.10719908,\n",
      "        -0.02585236, -0.37550124, -0.59261764, -1.13334063, -0.21033767],\n",
      "       [-0.43664434, -1.39479159, -1.69268381, -0.94948049, -1.27133524,\n",
      "        -0.70130297, -1.33301927, -0.81116035, -1.07527586, -1.66143407],\n",
      "       [-0.45148065, -0.91159968, -1.03189045, -1.10330699, -0.22954374,\n",
      "        -1.23667512, -1.15779083, -1.13007106,  0.11576962, -1.59387454],\n",
      "       [-1.2342925 ,  0.22825142, -0.52002247, -0.94077492, -1.31173937,\n",
      "        -0.04128284, -0.60117536, -0.52280868, -0.14590897, -0.16754535],\n",
      "       [-1.38041727,  0.0245013 , -0.88616725, -1.41358959, -0.71826232,\n",
      "        -0.9898886 , -1.22985433, -0.52484158, -1.2708501 , -1.64708579]])]\n"
     ]
    }
   ],
   "source": [
    "final_weights, final_biases = gradient_descent(weights, biases, trainingdata,\n",
    "                                              traininganswervectors, 5, 1, 30)\n",
    "\n",
    "print(final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
