{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.html.widgets import interact\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "sigmoid_v = np.vectorize(sigmoid)\n",
    "\n",
    "def sigmoidprime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "sigmoidprime_v = np.vectorize(sigmoidprime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#64 inputs, 12 hidden, 10 out\n",
    "\n",
    "weights = [np.random.rand(64, 20) * 2 - 1, np.random.rand(20, 10) * 2 - 1]\n",
    "biases = [np.random.rand(20) * 2 - 1, np.random.rand(10) * 2 - 1]\n",
    "trainingdata = digits.data[0:1200]\n",
    "traininganswers = digits.target[0:1200]\n",
    "lc = 0.02\n",
    "\n",
    "traininganswervectors = np.zeros((1796,10))\n",
    "for n in range(1796):\n",
    "    traininganswervectors[n][digits.target[n]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.73070924, -0.0036695 ,  0.37261072, -0.12130895,  0.56922745,\n",
      "       -0.91708692, -0.08453268, -0.78320633, -0.87084125, -0.83185793,\n",
      "        0.56216944,  0.49383069,  0.80252436,  0.84822477,  0.08645544,\n",
      "        0.75493412, -0.03975971,  0.51079688, -0.17167827,  0.73049849]), array([ 0.61851411, -0.26729076,  0.11198005,  0.33326213,  0.1795887 ,\n",
      "       -0.40762369,  0.07931904, -0.20830035, -0.92994015, -0.67726018])]\n"
     ]
    }
   ],
   "source": [
    "size = [64, 20, 10]\n",
    "\n",
    "weights = []\n",
    "for n in range(1, len(size)):\n",
    "    weights.append(np.random.rand(size[n-1], size[n]) * 2 - 1)\n",
    "    \n",
    "biases = []\n",
    "for n in range(1, len(size)):\n",
    "    biases.append(np.random.rand(size[n]) * 2 - 1)\n",
    "\n",
    "trainingdata = digits.data[0:1200]\n",
    "traininganswers = digits.target[0:1200]\n",
    "lc = 0.02\n",
    "\n",
    "traininganswervectors = np.zeros((1796,10))\n",
    "for n in range(1796):\n",
    "    traininganswervectors[n][digits.target[n]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feedforward(a, weights, biases):\n",
    "    #for each hidden, calculate the value based on the inputs\n",
    "    b = np.zeros(20)\n",
    "    for n in range(20):\n",
    "        b[n] = sigmoid_v(np.dot(weights[0][0:,n], a)) + biases[0][n]\n",
    "    \n",
    "    #for each output, calculate based on hidden\n",
    "    c = np.zeros(10)\n",
    "    for n2 in range(10):\n",
    "        c[n2] = sigmoid_v(np.dot(weights[1][0:,n2], b)) + biases[1][n2]\n",
    "        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   5.  13.   9.   1.   0.   0.   0.   0.  13.  15.  10.  15.   5.\n",
      "   0.   0.   3.  15.   2.   0.  11.   8.   0.   0.   4.  12.   0.   0.   8.\n",
      "   8.   0.   0.   5.   8.   0.   0.   9.   8.   0.   0.   4.  11.   0.   1.\n",
      "  12.   7.   0.   0.   2.  14.   5.  10.  12.   0.   0.   0.   0.   6.  13.\n",
      "  10.   0.   0.   0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.43704666,  0.01691983,  0.09181134,  0.98763505,  1.4865199 ,\n",
       "        0.71999403,  1.19331762,  0.43169264,  0.81842977,  1.12723021])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs)\n",
    "feedforward(inputs, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GradientDescent(inputs, results, batchsize, lc, epochs):\n",
    "    for n in range(epochs):\n",
    "        #pick random locations for input/result data\n",
    "        locations = np.random.randint(0, len(inputs), batchsize)\n",
    "        minibatch = []\n",
    "        #create tuples (inputs, result) based on random locations\n",
    "        for n2 in batchsize:\n",
    "            minibatch.append((inputs[locations[n2]], results[locations[n2]]))\n",
    "        for n3 in range(batchsize):\n",
    "            train(minibatch[n3], lc)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(minibatch, lc):\n",
    "    nw = weights\n",
    "    nb = bias\n",
    "    dnb, dnw = backprop(inputs, results)\n",
    "    for n in range(len(minibatch)):\n",
    "        nb = nb+dnb\n",
    "        nw = nw+dnw\n",
    "        \n",
    "    weights = w-(lc/len(minibatch))*nw\n",
    "    biases = b-(lc/len(minibatch))*nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def backprop(b, inputs, results):\n",
    "    nw = weights\n",
    "    nb = bias\n",
    "    zlist = []\n",
    "    alist = []\n",
    "    for n in range(10):\n",
    "        zlist[1][n] = np.dot(weights[1][0:,n], b) + biases[1][n]\n",
    "        alist[1][n] = sigmoid_v(zlist[1][n])\n",
    "    for n2 in range(20):\n",
    "        zlist[0][n2] = np.dot(weights[0][0:,n2], b) + biases[0][n2]\n",
    "        alist = sigmoid_v(zlist[0][n])\n",
    "        \n",
    "    delta = costderivative(alist[1], results) * sigmoidprime_v(zlist[1])\n",
    "    \n",
    "    nb[1] = delta\n",
    "    nw[1] = np.dot(delta, alist[1].transpose())\n",
    "    \n",
    "    sigprime = sigmoidprime_v(zlist[0])\n",
    "    delta = np.dot(weights[0], delta) * sigprime\n",
    "    nb[0] = delta\n",
    "    nw[0] = np.dot(delta, alist[0].transpose())\n",
    "    \n",
    "    return nb, nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def costderivative(output, answers):\n",
    "    return (output - answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(inputs, results, answers):\n",
    "    correct = 0\n",
    "    for n in range(0, len(results)):\n",
    "        if results[n] == answers[n]:\n",
    "            correct += 1\n",
    "    return correct / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n in len(trainingdata):\n",
    "    ffwd = feedforward(trainingdata[n], weights, biases)\n",
    "    GradientDescent(ffwd, traininganswervectors[n], 5, 0.05, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
