{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.html.widgets import interact\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "sigmoid_v = np.vectorize(sigmoid)\n",
    "\n",
    "def sigmoidprime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "sigmoidprime_v = np.vectorize(sigmoidprime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = [64, 20, 10]\n",
    "\n",
    "weights = []\n",
    "for n in range(1, len(size)):\n",
    "    weights.append(np.random.rand(size[n], size[n-1]) * 2 - 1)\n",
    "\n",
    "biases = []\n",
    "for n in range(1, len(size)):\n",
    "    biases.append(np.random.rand(size[n]) * 2 - 1)\n",
    "\n",
    "trainingdata = digits.data[0:1200]\n",
    "traininganswers = digits.target[0:1200]\n",
    "lc = 0.02\n",
    "\n",
    "#convert the integer answers into a 10-dimension array\n",
    "traininganswervectors = np.zeros((1796,10))\n",
    "for n in range(1796):\n",
    "    traininganswervectors[n][digits.target[n]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feedforward(weights, biases, a):\n",
    "    b = []\n",
    "    #first element is inputs \"a\"\n",
    "    b.append(a)\n",
    "    for n in range(1, len(size)):\n",
    "        #all other elements depend on the number of neurons\n",
    "        b.append(np.zeros(size[n]))\n",
    "        for n2 in range(0, size[n]):\n",
    "            b[n][n2] = sigmoid_v(np.dot(weights[n-1][n2], b[n-1]) + biases[n-1][n2])\n",
    "      \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95268903  0.15219509  0.37781353  0.0787356   0.89811514  0.20636925\n",
      "  0.40752871  0.4777203   0.96000983  0.14310585]\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[-0.04731097  0.15219509  0.37781353  0.0787356   0.89811514  0.20636925\n",
      "  0.40752871  0.4777203   0.96000983  0.14310585]\n"
     ]
    }
   ],
   "source": [
    "opt = feedforward(weights, biases, trainingdata[0])\n",
    "print(opt[-1])\n",
    "print(traininganswervectors[0])\n",
    "print(costderivative(opt[-1], traininganswervectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent(weights, biases, inputs, answers, batchsize, lc, epochs):\n",
    "    for n in range(epochs):\n",
    "        #pick random locations for input/result data\n",
    "        locations = np.random.randint(0, len(inputs), batchsize)\n",
    "        minibatch = []\n",
    "        #create tuples (inputs, result) based on random locations\n",
    "        for n2 in range(batchsize):\n",
    "            minibatch.append((inputs[locations[n2]], answers[locations[n2]]))\n",
    "        for n3 in range(batchsize):\n",
    "            weights, biases = train(weights, biases, minibatch, lc)\n",
    "        \n",
    "        \n",
    "        results = []\n",
    "        for n4 in range(len(trainingdata)):\n",
    "            results.append(feedforward(weights, biases, inputs[n4])[-1])\n",
    "            \n",
    "        accresult = accuracy(inputs, results, answers)\n",
    "        print(\"Epoch \", n, \" : \", accresult)\n",
    "        \n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(weights, biases, minibatch, lc):\n",
    "    #set the nabla functions to be the functions themselves initially, same size\n",
    "    nb = [np.zeros(b.shape) for b in biases]\n",
    "    nw = [np.zeros(w.shape) for w in weights]\n",
    "    #largely taken from Michael Nielsen's implementation\n",
    "    for i, r in minibatch:\n",
    "        dnb, dnw = backprop(weights, biases, i, r)\n",
    "        nb = [a+b for a, b in zip(nb, dnb)]\n",
    "        nw = [a+b for a, b in zip(nw, dnw)]\n",
    "    \n",
    "    weights = [w-(lc/len(minibatch))*n_w for w, n_w in zip(weights, nw)]\n",
    "    biases = [b-(lc/len(minibatch))*n_b for b, n_b in zip(biases, nb)]\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def backprop(weights, biases, inputs, answers):\n",
    "    #set the nabla functions to be the same size as functions\n",
    "    nb = [np.zeros(b.shape) for b in biases]\n",
    "    nw = [np.zeros(w.shape) for w in weights]\n",
    "    a = inputs\n",
    "    alist = [inputs]\n",
    "    zlist = []\n",
    "    for b, w in zip(biases, weights):\n",
    "            z = np.dot(w, a)+b\n",
    "            zlist.append(z)\n",
    "            a = sigmoid_v(z)\n",
    "            alist.append(a)\n",
    "    \n",
    "    delta = costderivative(alist[-1], answers) * sigmoidprime_v(zlist[-1])\n",
    "    nb[-1] = delta\n",
    "    print(\"delta\", delta)\n",
    "    print(\"alist\", alist)\n",
    "    #different from MN, alist[-2] not same size as delta?\n",
    "    nw[-1] = np.dot(delta, alist[-2].transpose())\n",
    "    \n",
    "    for n in range(2, len(size)):\n",
    "        delta = np.dot(weights[-n+1].transpose(), delta) * sigmoidprime_v(zlist[-n])\n",
    "        nb[-n] = delta\n",
    "        #same here\n",
    "        nw[-n] = np.dot(delta, alist[-n-1].transpose())\n",
    "    \n",
    "    return nb, nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def costderivative(output, answers):\n",
    "    return (output - answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(inputs, results, answers):\n",
    "    correct = 0\n",
    "    binresults = results\n",
    "    for n in range(0, len(results)):\n",
    "        #converts the output into a binary y/n for each digit\n",
    "        for n2 in range(len(results[n])):\n",
    "            if results[n][n2] == np.amax(results[n]):\n",
    "                binresults[n][n2] = 1\n",
    "            else:\n",
    "                binresults[n][n2] = 0\n",
    "        \n",
    "        if np.array_equal(answers[n], binresults[n]):\n",
    "            correct += 1\n",
    "    return correct / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = [64, 20, 10]\n",
    "\n",
    "weights = []\n",
    "for n in range(1, len(size)):\n",
    "    weights.append(np.random.rand(size[n], size[n-1]) * 2 - 1)\n",
    "\n",
    "biases = []\n",
    "for n in range(1, len(size)):\n",
    "    biases.append(np.random.rand(size[n]) * 2 - 1)\n",
    "\n",
    "trainingdata = digits.data[0:500]\n",
    "traininganswers = digits.target[0:500]\n",
    "\n",
    "traininganswervectors = np.zeros((500,10))\n",
    "for n in range(500):\n",
    "    traininganswervectors[n][digits.target[n]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta [ 0.07675723  0.02780815  0.0093905   0.13425283  0.03234364  0.14556868\n",
      "  0.00592747  0.07448789 -0.09589887  0.00622013]\n",
      "alist [array([  0.,   0.,   5.,  14.,  15.,   2.,   0.,   0.,   0.,   0.,  13.,\n",
      "        14.,   9.,  10.,   0.,   0.,   0.,   0.,  15.,   8.,   2.,  15.,\n",
      "         3.,   0.,   0.,   0.,  11.,  12.,   9.,  14.,   2.,   0.,   0.,\n",
      "         0.,   7.,  16.,  14.,   2.,   0.,   0.,   0.,   0.,  13.,  14.,\n",
      "        16.,   4.,   0.,   0.,   0.,   3.,  15.,   8.,  14.,  10.,   0.,\n",
      "         0.,   0.,   0.,   6.,  16.,  16.,   8.,   0.,   0.]), array([  8.71512058e-16,   1.34421193e-03,   1.00000000e+00,\n",
      "         1.41393057e-02,   1.00000000e+00,   1.00000000e+00,\n",
      "         1.32874316e-07,   9.99999962e-01,   1.28709646e-20,\n",
      "         1.00000000e+00,   1.00000000e+00,   6.37924075e-01,\n",
      "         9.99895559e-01,   1.00000000e+00,   1.00000000e+00,\n",
      "         9.99999999e-01,   1.00000000e+00,   9.99996665e-01,\n",
      "         4.54852532e-03,   4.59835385e-04]), array([ 0.90661599,  0.18468104,  0.10227581,  0.77846156,  0.96528839,\n",
      "        0.61449925,  0.08027991,  0.91006188,  0.60031596,  0.08232965])]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (10,) and (20,) not aligned: 10 (dim 0) != 20 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-659cabab3c73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m final_weights, final_biases = gradient_descent(weights, biases, trainingdata,\n\u001b[1;32m----> 2\u001b[1;33m                                               traininganswervectors, 5, 1, 100)\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-1fc706aefe9d>\u001b[0m in \u001b[0;36mgradient_descent\u001b[1;34m(weights, biases, inputs, answers, batchsize, lc, epochs)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mminibatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlocations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlocations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn3\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-9425d8ff6f22>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(weights, biases, minibatch, lc)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#largely taken from Michael Nielsen's implementation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mdnb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdnw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdnb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mnw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdnw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-06514cc2ae65>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(weights, biases, inputs, answers)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"alist\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#different from MN, alist[-2] not same size as delta?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mnw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10,) and (20,) not aligned: 10 (dim 0) != 20 (dim 0)"
     ]
    }
   ],
   "source": [
    "final_weights, final_biases = gradient_descent(weights, biases, trainingdata,\n",
    "                                              traininganswervectors, 5, 1, 100)\n",
    "\n",
    "print(final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
